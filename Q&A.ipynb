{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucKZ2FbJ2XZC",
        "outputId": "7a21c4b2-f65b-42db-fb40-079879e4681a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/RAG')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0380eOgk3tjy",
        "outputId": "07b3d2f3-bd3c-4bd8-cbcc-dbab40a1b7c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\tanphat\\appdata\\roaming\\python\\python310\\site-packages (from faiss-cpu) (2.2.3)\n",
            "Requirement already satisfied: packaging in c:\\users\\tanphat\\appdata\\roaming\\python\\python310\\site-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.13.1)\n",
            "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
            "  Downloading huggingface_hub-0.31.4-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in c:\\users\\tanphat\\appdata\\roaming\\python\\python310\\site-packages (from accelerate) (6.1.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: Pillow in c:\\users\\tanphat\\appdata\\roaming\\python\\python310\\site-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.2.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\tanphat\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
            "Downloading faiss_cpu-1.11.0-cp310-cp310-win_amd64.whl (15.0 MB)\n",
            "   ---------------------------------------- 0.0/15.0 MB ? eta -:--:--\n",
            "   --------- ------------------------------ 3.7/15.0 MB 27.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  14.9/15.0 MB 47.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 15.0/15.0 MB 41.1 MB/s eta 0:00:00\n",
            "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
            "   ---------------------------------------  10.2/10.4 MB 53.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 10.4/10.4 MB 43.3 MB/s eta 0:00:00\n",
            "Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
            "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
            "Downloading huggingface_hub-0.31.4-py3-none-any.whl (489 kB)\n",
            "Downloading PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
            "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
            "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
            "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.4/2.4 MB 46.2 MB/s eta 0:00:00\n",
            "Installing collected packages: safetensors, pyyaml, faiss-cpu, huggingface-hub, tokenizers, accelerate, transformers, sentence-transformers\n",
            "Successfully installed accelerate-1.7.0 faiss-cpu-1.11.0 huggingface-hub-0.31.4 pyyaml-6.0.2 safetensors-0.5.3 sentence-transformers-4.1.0 tokenizers-0.21.1 transformers-4.51.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\tanphat\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu transformers accelerate sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "uPbLKoAZ4Hi4",
        "outputId": "d09fa89e-c37a-42db-d4b4-b997d67d0747"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import json\n",
        "\n",
        "\n",
        "# Load FAISS index\n",
        "index = faiss.read_index(\"embeddings/index.faiss\")\n",
        "\n",
        "# Load lại văn bản gốc của các chunk\n",
        "with open(\"embeddings/chunk_texts.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    texts = json.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1GRgq8fC5FFM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\TANPHAT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "c:\\Users\\TANPHAT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\TANPHAT\\.cache\\huggingface\\hub\\models--bkai-foundation-models--vietnamese-bi-encoder. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "bi_encoder = SentenceTransformer(\"bkai-foundation-models/vietnamese-bi-encoder\")\n",
        "\n",
        "def retrieve_context(query, top_k=10):\n",
        "    query_embedding = bi_encoder.encode([query])\n",
        "    _, indices = index.search(np.array(query_embedding), k=top_k)\n",
        "    return \"\\n\".join([texts[i] for i in indices[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Pinging huggingface.co [108.157.32.94] with 32 bytes of data:\n",
            "Reply from 108.157.32.94: bytes=32 time=23ms TTL=244\n",
            "Reply from 108.157.32.94: bytes=32 time=22ms TTL=244\n",
            "Reply from 108.157.32.94: bytes=32 time=23ms TTL=244\n",
            "Reply from 108.157.32.94: bytes=32 time=22ms TTL=244\n",
            "\n",
            "Ping statistics for 108.157.32.94:\n",
            "    Packets: Sent = 4, Received = 4, Lost = 0 (0% loss),\n",
            "Approximate round trip times in milli-seconds:\n",
            "    Minimum = 22ms, Maximum = 23ms, Average = 22ms\n"
          ]
        }
      ],
      "source": [
        "!ping huggingface.co -n 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\TANPHAT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\TANPHAT\\.cache\\huggingface\\hub\\models--meta-llama--Llama-2-7b-chat-hf. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "c:\\Users\\TANPHAT\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "Fetching 2 files: 100%|██████████| 2/2 [06:08<00:00, 184.10s/it]\n",
            "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=token)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, use_auth_token=token, device_map=\"auto\")\n",
        "\n",
        "qa_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
